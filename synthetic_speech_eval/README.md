![Syn Eval Tool](../assets/syn-eval-tool.jpg)

## Overview
This part of the toolkit focuses on evaluating synthetic speech generated by voice anonymization systems. We provide following metrics:

### üó£Ô∏è Speech Evaluation Metrics

| **Metric** | **Short Description** | **Reference** |
|-------------|----------------------|----------------|
| **Word Error Rate (WER)** / **Character Error Rate (CER)** / **Phoneme Error Rate (PER)** | Measures recognition accuracy by comparing predicted vs. reference transcriptions (insertions, deletions, substitutions). | [Hinton et al., 2012](https://doi.org/10.1109/MSP.2012.2205597) |
| **Mel Cepstral Distortion (MCD-DTW)** | Quantifies the spectral distance between synthesized and reference speech using Mel cepstral coefficients aligned via Dynamic Time Warping (DTW). | [Kubichek, 1993](https://ieeexplore.ieee.org/document/287800) |
| **Speech MOS (Mean Opinion Score)** | Human-rated perceptual score (1‚Äì5) evaluating overall naturalness or quality of speech samples. | [ITU-T P.800](https://www.itu.int/rec/T-REC-P.800-199608-I/en) |
| **WV MOS (Weighted Voice MOS)** | Automatic neural predictor of MOS trained on large-scale human perception data; approximates human subjective ratings. | [Lo et al., 2019, *Interspeech*](https://arxiv.org/abs/1904.08352) |
| **Pitch Jensen‚ÄìShannon Divergence (JSD)** | Statistical divergence between pitch distributions of reference and generated speech, assessing pitch realism and variability. | [Shannon, 1948](https://doi.org/10.1002/j.1538-7305.1948.tb01338.x) |
| **Energy Jensen‚ÄìShannon Divergence (JSD)** | Measures similarity of energy contours or amplitude distributions between real and synthesized speech. | [Shannon, 1948](https://doi.org/10.1002/j.1538-7305.1948.tb01338.x) |
| **Speaker Similarity (Cosine Distance)** | Embedding-based similarity between generated and reference speaker voices; lower distance implies higher speaker consistency. | [Wan et al., 2018, *GE2E Speaker Embeddings*](https://arxiv.org/abs/1803.10963) |
| **Perceptual Evaluation of Speech Quality (PESQ)** | Objective measure of perceptual speech quality comparing degraded and reference signals; outputs MOS-like scores. | [ITU-T P.862](https://www.itu.int/rec/T-REC-P.862/en) |
| **Short-Time Objective Intelligibility (STOI)** | Predicts speech intelligibility in noisy conditions using short-time correlation between clean and degraded speech signals. | [Taal et al., 2011, *IEEE TASLP*](https://ieeexplore.ieee.org/document/5495701) |
| **WARP-Q** | Deep-learning-based perceptual speech quality metric using warping-based feature alignment and learned perceptual similarity. | [Jassim et al., 2021, *GitHub Repo*](https://github.com/wjassim/WARP-Q) |


## Usage

Kindly download the wvmos pretrained model from [this link]()
```bash
    conda create -n speech_quality python=3.9
    apt-get install espeak
    pip install -r requirements.txt
```


```bash
    python main.py --input_csv_path ./test_csvs/input.csv --output_csv_path ./test_csvs/test_out.csv --lang english --config_path ./test_csvs/eval.json
```

- Language options - english, german, french, italian

- This script generates 3 files 
    1) test_out.csv - Values for every data point
    2) test_out.txt - Avergae values for all metrics
    3) test_out.png - Phoneme and diphone error plot

See input.csv and output.csv for reference on formatting

## Note

Phoneme plot is based on alginments generated using jiwer library.
Ex alginment : 

    REF: h…ôllo ä
    HYP: h…ô**o ä
    Type:  DD 

We treat insertion, deletion and substituion w.r.t refernce as a mistake .
And count the same for every phoneme to generate the plots
